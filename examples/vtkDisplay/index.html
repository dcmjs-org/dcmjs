<!DOCTYPE HTML>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="user-scalable=no, width=device-width, initial-scale=1, maximum-scale=1">

    <link href="../css/bootstrap.min.css" rel="stylesheet">
</head>
<body>
<div class="container">
    <div class="page-header">
        <h1>
            Display DICOM Segmentation with VTK-JS
        </h1>
        <p>
            This example demonstrates how to display a DICOM Segmentation object with vtk-js.
        </p>
        <a href="../index.html">Go back to the Examples page</a>
    </div>

    <div class="row">
        <div class="col-xs-6">
          <h2>Status: </h2><p id="statusLine"></p>
          <h2>Volume:</h2>
            <div id="volumeViewer"> </div>
            <p>Sample data is from the dicom4qi connectathon event to be held at RSNA 2017.  This is <a href='https://qiicr.gitbooks.io/dicom4qi/content/instructions/seg.html#test-dataset-2'>test dataset #2</a>
        </div>
        <div class="col-xs-6">
            <div id="properties">
            </div>
        </div>
    </div>
</div>
</body>

<script src="../js/jquery.min.js"></script>
<script src="../js/jqueryFileDrop.js"></script>

<script src="../helpers/DICOMZero.js"></script>


<script src="https://unpkg.com/dicomweb-client"></script>
<script src="https://unpkg.com/dcmjs"></script>
<script src="https://unpkg.com/vtk.js"></script>

<script>
// custom slice interactor
const CustomSliceInteractorStyle = (function() {

const States = vtk.Rendering.Core.vtkInteractorStyle.States;

const SlicingMode = {
  I: 0,
  J: 1,
  K: 2,
};

function vtkCustomSliceInteractorStyle(publicAPI, model) {
  model.classHierarchy.push('vtkCustomSliceInteractorStyle');

  model.wlStartPos = [0, 0];
  model.zoomStartPos = [0, 0];

  publicAPI.handleStartMouseWheel = (callData) => {
    publicAPI.startSlice();
  };

  publicAPI.handleEndMouseWheel = (callData) => {
    publicAPI.endSlice();
  }

  publicAPI.handleMouseWheel = (callData) => {
    const renderer = callData.pokedRenderer;
    const camera = renderer.getActiveCamera();

    const dims = model.currentImage.getDimensions();
    const newSlice = Math.min(
      // negate spinY, since scrolling up is negative, and scrolling down is positive
      Math.max(0, model.slice - callData.spinY),
      // ignore last slice
      dims[model.slicingMode] - 2
    );

    publicAPI.setSlice(newSlice);

    publicAPI.invokeInteractionEvent({ type: 'InteractionEvent' });
  };

  const superHandleLeftButtonPress = publicAPI.handleLeftButtonPress;
  publicAPI.handleLeftButtonPress = (callData) => {
    model.wlStartPos[0] = callData.position.x;
    model.wlStartPos[1] = callData.position.y;

    if (!callData.shiftKey && !callData.controlKey) {
      const property = model.currentProperty;
      if (property) {
        model.initialMRange = property.getRGBTransferFunction(0).getMappingRange().slice();
        publicAPI.startWindowLevel();
      }
    } else if (superHandleLeftButtonPress) {
      superHandleLeftButtonPress(callData);
    }
  };

  const superHandleLeftButtonRelease = publicAPI.handleLeftButtonRelease;
  publicAPI.handleLeftButtonRelease = (callData) => {
    if (model.state === States.IS_WINDOW_LEVEL) {
      publicAPI.endWindowLevel();
    } else if (superHandleLeftButtonRelease) {
      superHandleLeftButtonRelease(callData);
    }
  };

  const superHandleRightButtonPress = publicAPI.handleRightButtonPress;
  publicAPI.handleRightButtonPress = (callData) => {
    model.zoomStartPos[0] = callData.position.x;
    model.zoomStartPos[1] = callData.position.y;

    if (!callData.shiftKey && !callData.controlKey) {
      model.initialAngle = callData.pokedRenderer.getActiveCamera().getViewAngle();
      publicAPI.startCameraPose();
    } else if (superHandleRightButtonPress) {
      superHandleRightButtonPress(callData);
    }
  };

  const superHandleRightButtonRelease = publicAPI.handleRightButtonRelease;
  publicAPI.handleRightButtonRelease = (callData) => {
    if (model.state === States.IS_CAMERA_POSE) {
      publicAPI.endCameraPose();
    } else if (superHandleRightButtonRelease) {
      superHandleRightButtonRelease(callData);
    }
  };

  const superHandleMouseMove = publicAPI.handleMouseMove;
  publicAPI.handleMouseMove = (callData) => {
    const pos = [callData.position.x, callData.position.y];
    const renderer = callData.pokedRenderer;

    if (model.state === States.IS_WINDOW_LEVEL) {
      publicAPI.windowLevel(renderer, pos);
      publicAPI.invokeInteractionEvent({ type: 'InteractionEvent' });
    } else if (model.state === States.IS_CAMERA_POSE) {
      publicAPI.zoom(renderer, pos);
      publicAPI.invokeInteractionEvent({ type: 'InteractionEvent' });
    } else {
      superHandleMouseMove(callData);
    }
  };

  publicAPI.windowLevel = (renderer, pos) => {
    const rwi = model.interactor;

    if (model.currentProperty) {
      const size = rwi.getView().getViewportSize(renderer);

      const win = model.initialMRange[1] - model.initialMRange[0];
      const level = (model.initialMRange[0] + model.initialMRange[1]) / 2.0;

      let dx = ((pos[0] - model.wlStartPos[0]) * 4.0) / size[0];
      let dy = ((pos[1] - model.wlStartPos[1]) * 4.0) / size[1];

      if (Math.abs(win) > 0.01) {
        dx *= win;
      } else {
        dx *= win < 0 ? -0.01 : 0.01;
      }
      if (Math.abs(level) > 0.01) {
        dy *= level;
      } else {
        dy *= level < 0 ? -0.01 : 0.01;
      }

      if (win < 0.0) {
        dx *= -1;
      }
      if (level < 0.0) {
        dy *= -1;
      }

      const newWin = Math.max(0.01, dx + win);
      const newLevel = level - dy;

      const lower = newLevel - newWin / 2.0;
      const upper = newLevel + newWin / 2.0;

      model.currentProperty.getRGBTransferFunction(0).setMappingRange(lower, upper);
    }
  };

  publicAPI.zoom = (renderer, pos) => {
    const camera = renderer.getActiveCamera();
    const dy = (pos[1] - model.zoomStartPos[1]) / 10.0;
    const newAngle = Math.max(1, Math.min(179, model.initialAngle + dy));
    camera.setViewAngle(newAngle);
  };

  publicAPI.setCurrentVolumeNumber = (i) => {
    const renderer = model.interactor.getCurrentRenderer();
    if (!renderer) {
      return;
    }
    model.currentVolumeNumber = i;

    function propMatch(j, prop, targetIndex) {
      return (
        prop.isA('vtkVolume') &&
        j === targetIndex &&
        prop.getPickable()
      );
    }

    const props = renderer.getViewProps();
    let targetIndex = i;
    if (i < 0) {
      targetIndex += props.length;
    }
    let prop = null;
    let foundProp = false;
    for (let j = 0; j < props.length && !foundProp; j++) {
      if (propMatch(j, props[j], targetIndex)) {
        foundProp = true;
        prop = props[j];
      }
    }

    if (prop) {
      model.currentProperty = prop.getProperty();
      model.currentImage = prop.getMapper().getInputData();
    }
  };

  publicAPI.setSlice = (slice) => {
    if (slice !== model.slice) {
      const sliceDelta = slice - model.slice;
      model.slice = slice;

      const renderer = model.interactor.getCurrentRenderer();
      const camera = renderer.getActiveCamera();
      const dop = camera.getDirectionOfProjection();

      const pos = camera.getPosition();
      const fp = camera.getFocalPoint();

      const deltaV = [
        sliceDelta * dop[0],
        sliceDelta * dop[1],
        sliceDelta * dop[2],
      ];

      pos[0] += deltaV[0];
      pos[1] += deltaV[1];
      pos[2] += deltaV[2];

      fp[0] += deltaV[0];
      fp[1] += deltaV[1];
      fp[2] += deltaV[2];

      camera.setPosition(...pos);
      camera.setFocalPoint(...fp);

      publicAPI.modified();
    }
  };

  publicAPI.setSlicingMode = (mode, force = false) => {
    if (force || mode !== model.slicingMode && mode >= 0 && mode < 3) {
      model.slicingMode = mode;

      const renderer = model.interactor.getCurrentRenderer();
      const camera = renderer.getActiveCamera();
      const dims = model.currentImage.getDimensions();

      const indexDOP = [0, 0, 0];
      indexDOP[mode] = 1;

      const worldDOP = [0, 0, 0];
      model.currentImage.indexToWorldVec3(indexDOP, worldDOP);

      // need to ignore translation for DOP transform
      // const indexToWorld = model.currentImage.getIndexToWorld();
      // // indexToWorld is column major
      // indexToWorld[12] = 0;
      // indexToWorld[13] = 0;
      // indexToWorld[14] = 0;

      // this is a replacement for the incomplete code above, but has
      // numerical accuracy issues due worldDOP already having gone through
      // a transformation
      const origin = model.currentImage.getOrigin();
      worldDOP[0] -= origin[0];
      worldDOP[1] -= origin[1];
      worldDOP[2] -= origin[2];

      // set camera focal point and position
      const fpIndex = [
        (dims[0] - 1) / 2,
        (dims[1] - 1) / 2,
        (dims[2] - 1) / 2,
      ];
      fpIndex[mode] = model.slice;

      const widthVectIndex = [0, 0, 0];
      widthVectIndex[mode] = dims[mode];

      // world space
      const fpWorld = [0, 0, 0];
      const widthVectWorld = [0, 0, 0];
      model.currentImage.indexToWorldVec3(fpIndex, fpWorld);
      model.currentImage.indexToWorldVec3(widthVectIndex, widthVectWorld);

      // ignore translation
      widthVectWorld[0] -= origin[0];
      widthVectWorld[0] -= origin[1];
      widthVectWorld[0] -= origin[2];

      const width = Math.sqrt(vtk.Common.Core.vtkMath.dot(widthVectWorld, widthVectWorld));
      // reset zoom angle to 90
      const angle = 90;
      const d = width / (2 * Math.tan(angle / 360 * Math.PI));

      const newPos = [
        fpWorld[0] - d * worldDOP[0],
        fpWorld[1] - d * worldDOP[1],
        fpWorld[2] - d * worldDOP[2],
      ];

      // some epsilon, otherwise the volume doesn't show up?
      fpWorld[mode] += 1 / 65536;

      camera.setPosition(...newPos);
      camera.setFocalPoint(...fpWorld);
      camera.setViewAngle(angle);

      camera.setClippingRange(d, d+1);
    }
  };
}

const INITIAL_VALUES = {
  slice: 0,
  slicingMode: SlicingMode.K,
  autoAdjustCameraClippingRange: false,
};

function extend(publicAPI, model, initialValues) {
  Object.assign(model, INITIAL_VALUES, initialValues || {});

  vtk.Interaction.Style.vtkInteractorStyleTrackballCamera.extend(publicAPI, model, initialValues || {});

  vtk.macro.setGet(publicAPI, model, ['slicingMode']);
  vtk.macro.get(publicAPI, model, ['slice']);

  vtkCustomSliceInteractorStyle(publicAPI, model);
}

const newInstance = vtk.macro.newInstance(extend, 'vtkCustomSliceInteractorStyle');

return Object.freeze({ newInstance, extend, SlicingMode });

})();

</script>

<script>
  let volumeViewer;
  let vtkVolumeActors = [];
  let vtkImageSliceActors = [];
  let controllerWidgets = [];
  let segments = {};

  $(document).ready(function() {

    //
    // set up the volume viewer
    //
    let volumeElement = document.getElementById('volumeViewer');

    volumeViewer = vtk.Rendering.Misc.vtkGenericRenderWindow.newInstance({
        background: [0, 0, 0],
    });
    const volumeRenderWindow = volumeViewer.getRenderWindow();
    const volumeRenderer = volumeViewer.getRenderer();

    volumeElement.innerHTML = '';
    volumeViewer.setContainer(volumeElement);

    // uses dataset for common elements but perFrame to override
    // (for multiple segments)
    function geometryFromFunctionalGroups(dataset, perFrame) {
      const vtkMath = vtk.Common.Core.vtkMath;
      let pixelMeasures = dataset.SharedFunctionalGroupsSequence.PixelMeasuresSequence;
      let planeOrientation = dataset.SharedFunctionalGroupsSequence.PlaneOrientationSequence;
      let planePosition = perFrame[0].PlanePositionSequence; // TODO: assume sorted frames!

      const geometry = {};

      // NB: DICOM PixelSpacing is defined as Row then Column,
      // unlike ImageOrientationPatient
      geometry.spacing = [pixelMeasures.PixelSpacing[1],
                          pixelMeasures.PixelSpacing[0],
                          pixelMeasures.SpacingBetweenSlices].map(Number);

      geometry.dimensions = [dataset.Columns,
                             dataset.Rows,
                             perFrame.length].map(Number);

      let orientation = planeOrientation.ImageOrientationPatient.map(Number);
      const columnStepToPatient = orientation.slice(0,3);
      const rowStepToPatient = orientation.slice(3,6);
      geometry.planeNormal = [];
      vtkMath.cross(columnStepToPatient, rowStepToPatient, geometry.planeNormal);

      let firstPosition = perFrame[0].PlanePositionSequence.ImagePositionPatient.map(Number);
      let lastPosition = perFrame[perFrame.length-1].PlanePositionSequence.ImagePositionPatient.map(Number);
      geometry.sliceStep = [];
      vtkMath.subtract(lastPosition, firstPosition, geometry.sliceStep);
      vtkMath.normalize(geometry.sliceStep);
      geometry.direction = columnStepToPatient.concat(rowStepToPatient).concat(geometry.sliceStep);
      geometry.origin = planePosition.ImagePositionPatient.map(Number);

      return(geometry);
    }

    //
    // takes the arraybuffer of dicom data and returns
    // a vtkVolume (actor) ready to render
    //
    function part10ToVolumeActor(part10) {

      dataset = DICOMZero.datasetFromArrayBuffer(part10);

      const scalarArray = vtk.Common.Core.vtkDataArray.newInstance({
          name: "Scalars",
          numberOfComponents: dataset.SamplesPerPixel,
          values: new Int16Array(dataset.PixelData),
      });

      const imageData = vtk.Common.DataModel.vtkImageData.newInstance();
      imageData.getPointData().setScalars(scalarArray);

      geometry = geometryFromFunctionalGroups(dataset, dataset.PerFrameFunctionalGroupsSequence);
      imageData.setDimensions(geometry.dimensions);
      imageData.setSpacing(geometry.spacing);
      imageData.setOrigin(geometry.origin);
      imageData.setDirection(geometry.direction);

      const mapper = vtk.Rendering.Core.vtkVolumeMapper.newInstance();
      mapper.setInputData(imageData);
      mapper.setSampleDistance(2.);

      const actor = vtk.Rendering.Core.vtkVolume.newInstance();
      actor.setMapper(mapper);

      return actor;
    }

    function part10ToSEGVolumeActors(part10) {

      dataset = DICOMZero.datasetFromArrayBuffer(part10);
      if (dataset.SegmentSequence.constructor.name !== "Array") {
        dataset.SegmentSequence = [dataset.SegmentSequence];
      }
      dataset.SegmentSequence.forEach(segment => {

        // TODO: other interesting fields could be extracted from the segment

        // color for making the lookup table
        const cielab = segment.RecommendedDisplayCIELabValue;
        const rgba = dcmjs.data.Colors.dicomlab2RGB(cielab).map(x => Math.round(x * 255));
        rgba.push(255);

        segments[segment.SegmentNumber] = {
          color: rgba,
          functionalGroups: [],
          offset: null,
          size: null,
          pixelData: null,
        }

      });

      // make a list of functional groups per segment
      dataset.PerFrameFunctionalGroupsSequence.forEach(functionalGroup => {
        let segmentNumber = functionalGroup.SegmentIdentificationSequence.ReferencedSegmentNumber;
        segments[segmentNumber].functionalGroups.push(functionalGroup);
      });

      // determine per-segment index into the pixel data
      // TODO: only handles one-bit-per pixel
      const actors = [];
      let frameSize = Math.ceil(dataset.Rows * dataset.Columns / 8);
      let nextOffset = 0;
      Object.keys(segments).forEach(segmentKey => {
        const segment = segments[segmentKey];
        segment.numberOfFrames = segment.functionalGroups.length;
        segment.size = segment.numberOfFrames * frameSize;
        segment.offset = nextOffset;
        nextOffset  = segment.offset + segment.size
        const packedSegment = dataset.PixelData.slice(segment.offset, nextOffset);
        segment.pixelData = dcmjs.data.BitArray.unpack(packedSegment);

        // now make actors using the segment information
        const scalarArray = vtk.Common.Core.vtkDataArray.newInstance({
            name: "Scalars",
            numberOfComponents: 1,
            values: segment.pixelData,
        });

        const imageData = vtk.Common.DataModel.vtkImageData.newInstance();
        imageData.getPointData().setScalars(scalarArray);

        geometry = geometryFromFunctionalGroups(dataset, segment.functionalGroups);
        imageData.setDimensions(geometry.dimensions);
        imageData.setSpacing(geometry.spacing);
        imageData.setOrigin(geometry.origin);
        imageData.setDirection(geometry.direction);

        const mapper = vtk.Rendering.Core.vtkVolumeMapper.newInstance();
        mapper.setInputData(imageData);
        mapper.setSampleDistance(2.);

        const actor = vtk.Rendering.Core.vtkVolume.newInstance();
        actor.setMapper(mapper);

        actors.push(actor);
      });

      return(actors);
    }

    function downloadAndDisplaySampleData() {

      const urlRoot = 'https://s3.amazonaws.com/IsomicsPublic/SampleData/rsna2017/seg/task2/'
      let backgroundURL = urlRoot + 'PT-multiframe.dcm';
      let segURL = urlRoot + 'SEG/tumor_User1_Manual_Trial1.dcm';

      backgroundURL = 'https://s3.amazonaws.com/IsomicsPublic/SampleData/MRHead/MRHead-multiframe.dcm';
      //segURL = 'https://s3.amazonaws.com/IsomicsPublic/SampleData/MRHead/MRHead-segmentation.dcm';
      segURL = 'https://s3.amazonaws.com/IsomicsPublic/SampleData/MRHead/aseg-t1space.dcm';

      let status = (text) => {
        $('p#statusLine').text(text);
      };
      let downloadProgress = (event) => {
        status(`Downloading... ${Number(100 * event.loaded / event.total).toFixed(2)}%`);
      };

      const client = new DICOMwebClient.api.DICOMwebClient({});
      var backgroundPromise = client._httpGet(backgroundURL, {}, "arraybuffer", downloadProgress);
      var segPromise = client._httpGet(segURL, {}, "arraybuffer", downloadProgress);

      //
      // once the images have been loaded
      //
      Promise.all([backgroundPromise, segPromise]).then(values => {
        status('Processing...');
        setTimeout(() => {
          const backgroundPart10 = values[0];
          const segPart10 = values[1];

          //
          // volume
          //
          vtkVolumeActors.push(part10ToVolumeActor(backgroundPart10));
          const segActors = part10ToSEGVolumeActors(segPart10);
          vtkVolumeActors = vtkVolumeActors.concat(segActors);
          vtkVolumeActors.forEach((volume, volumeIndex) => {
            volumeRenderer.addVolume(volume);
          });

          volumeRenderer.resetCamera();
          volumeRenderer.getActiveCamera().setViewUp(0, 0, 1);
          let bounds = vtkVolumeActors[0].getBounds();
          let center = [ (bounds[0] + bounds[1]) / 2.,
                         (bounds[2] + bounds[3]) / 2.,
                         (bounds[4] + bounds[5]) / 2.];
          let position = center.slice();
          position[1] -= 4.25 * (-bounds[2] - center[1]);
          volumeRenderer.getActiveCamera().setPosition(...position);
          volumeRenderer.getActiveCamera().setFocalPoint(...center);

          volumeRenderer.updateLightsGeometryToFollowCamera();
          status('Rendering...');
          setTimeout(() => {
            volumeRenderWindow.render(); // first render setus up default lookup tables
            createLookupTables();
            volumeRenderWindow.render(); // second render displays correct colors

            status('Click and drag the left mouse button to rotate rotate the slice plane');
          }, 0);
        }, 0);
      });
    }

    window.addEventListener('resize', function() {
      console.log('need to resize the vtk window');
    });
    window.dispatchEvent(new Event('resize'));

    downloadAndDisplaySampleData();

  });

  function createLookupTables() {

    vtkVolumeActors.forEach((volume, volumeIndex) => {
      volume.getMapper().setSampleDistance(.25);
      volume.getMapper().setMaximumSamplesPerRay(2000);
      volume.getProperty().setUseGradientOpacity(0, false);

      let backgroundProperty = volume.getProperty().get();
      let backgroundComponent = backgroundProperty.componentData[0];

      sotf = backgroundComponent.scalarOpacity;
      sotf.removeAllPoints();
      let range, lowRangeOpacity;
      if (volumeIndex === 0) {
        // background is fully opaque
        range = volume.getMapper().getInputData().getPointData().getScalars().getRange()
        lowRangeOpacity = 1;
      } else {
        // segments are non-opaque at value 0, and fully opaque at 255
        range = [0,255];
        lowRangeOpacity = 0;
      }
      sotf.addPoint(range[0], lowRangeOpacity);
      sotf.addPoint(range[1], 1);

      rgbtf = backgroundComponent.rGBTransferFunction;
      rgbtf.removeAllPoints();
      rgbtf.addRGBPoint(range[0], 0,0,0);
      rgbtf.addRGBPoint(range[1], 1,1,1);
    });

    // segment colors
    Object.keys(segments).forEach(segmentIndex => {
      let vtkColor = segments[segmentIndex].color.slice(0,3).map(e => e / 255.);
      vtkVolumeActors[segmentIndex].getProperty().getRGBTransferFunction(0).setNodeValue(1, [1, ...vtkColor, .5, 0])
    });


    // set custom interactor style here
    const istyle = CustomSliceInteractorStyle.newInstance();
    volumeViewer.getRenderWindow().getInteractor().setInteractorStyle(istyle);

    istyle.setCurrentVolumeNumber(0); // background volume
    istyle.setSlice(40);
    istyle.setSlicingMode(2, true); // force set slice mode
  }
</script>
</html>
